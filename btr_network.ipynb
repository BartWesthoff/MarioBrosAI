{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac35e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# ------------------------------\n",
    "# Spectral Norm Residual Block\n",
    "# ------------------------------\n",
    "class SpectralBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.utils.spectral_norm(nn.Conv2d(in_channels, out_channels, 3, padding=1))\n",
    "        self.conv2 = nn.utils.spectral_norm(nn.Conv2d(out_channels, out_channels, 3, padding=1))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.skip = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        return self.relu(out + self.skip(x))\n",
    "\n",
    "# ------------------------------\n",
    "# Impala CNN Feature Extractor\n",
    "# ------------------------------\n",
    "class ImpalaCNN(nn.Module):\n",
    "    def __init__(self, in_channels=4):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            SpectralBlock(32, 32),\n",
    "            SpectralBlock(32, 32)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            SpectralBlock(32, 64),\n",
    "            SpectralBlock(64, 64)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            SpectralBlock(64, 64),\n",
    "            SpectralBlock(64, 64)\n",
    "        )\n",
    "        self.pool = nn.AdaptiveMaxPool2d((6, 6))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / 255.0  # Normalize input\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.pool(x)\n",
    "        return x  # shape: [B, 64, 6, 6]\n",
    "\n",
    "# ------------------------------\n",
    "# IQN Embedding Layer\n",
    "# ------------------------------\n",
    "class IQNEmbedding(nn.Module):\n",
    "    def __init__(self, n_cos=64, embedding_dim=64*6*6):\n",
    "        super().__init__()\n",
    "        self.n_cos = n_cos\n",
    "        self.linear = nn.Linear(n_cos, embedding_dim)\n",
    "\n",
    "    def forward(self, taus):\n",
    "        batch_size, n_quantiles = taus.shape\n",
    "        i = torch.arange(1, self.n_cos + 1, device=taus.device).float().view(1, 1, -1)\n",
    "        cosines = torch.cos(i * math.pi * taus.unsqueeze(-1))\n",
    "        out = F.relu(self.linear(cosines.view(batch_size * n_quantiles, -1)))\n",
    "        return out.view(batch_size, n_quantiles, -1)\n",
    "\n",
    "# ------------------------------\n",
    "# Noisy Linear Layer\n",
    "# ------------------------------\n",
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, sigma_init=0.5):\n",
    "        super().__init__()\n",
    "        self.mu_w = nn.Parameter(torch.empty(out_features, in_features))\n",
    "        self.sigma_w = nn.Parameter(torch.full((out_features, in_features), sigma_init))\n",
    "        self.mu_b = nn.Parameter(torch.empty(out_features))\n",
    "        self.sigma_b = nn.Parameter(torch.full((out_features,), sigma_init))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        mu_range = 1 / math.sqrt(self.mu_w.size(1))\n",
    "        self.mu_w.data.uniform_(-mu_range, mu_range)\n",
    "        self.mu_b.data.uniform_(-mu_range, mu_range)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            noise_w = torch.randn_like(self.mu_w)\n",
    "            noise_b = torch.randn_like(self.mu_b)\n",
    "            return F.linear(x, self.mu_w + self.sigma_w * noise_w, self.mu_b + self.sigma_b * noise_b)\n",
    "        else:\n",
    "            return F.linear(x, self.mu_w, self.mu_b)\n",
    "\n",
    "# ------------------------------\n",
    "# Full BTR Network\n",
    "# ------------------------------\n",
    "class BTRNetwork(nn.Module):\n",
    "    def __init__(self, num_actions, n_quantiles=8, n_cos=64):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = ImpalaCNN()\n",
    "        self.quantile_embedding = IQNEmbedding(n_cos)\n",
    "        self.n_quantiles = n_quantiles\n",
    "\n",
    "        fc_input_dim = 64 * 6 * 6\n",
    "\n",
    "        # Value Stream\n",
    "        self.value_stream = nn.Sequential(\n",
    "            NoisyLinear(fc_input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            NoisyLinear(512, 1)\n",
    "        )\n",
    "\n",
    "        # Advantage Stream\n",
    "        self.advantage_stream = nn.Sequential(\n",
    "            NoisyLinear(fc_input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            NoisyLinear(512, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Sample taus\n",
    "        taus = torch.rand(batch_size, self.n_quantiles, device=x.device)\n",
    "        phi = self.quantile_embedding(taus)\n",
    "\n",
    "        features = self.feature_extractor(x)  # shape: [B, 64, 6, 6]\n",
    "        features = features.view(batch_size, -1).unsqueeze(1).expand(-1, self.n_quantiles, -1)\n",
    "        x = phi * features  # Hadamard product\n",
    "\n",
    "        # Flatten quantile dimension into batch\n",
    "        x = x.view(batch_size * self.n_quantiles, -1)\n",
    "\n",
    "        value = self.value_stream(x)\n",
    "        advantage = self.advantage_stream(x)\n",
    "        q_values = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        return q_values.view(batch_size, self.n_quantiles, -1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
