{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45a4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from btr.Agent import Agent\n",
    "from utils_func import agent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9798cec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jump_right', 'sprint_right', 'move_right', 'move_left', 'none']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTION_KEYS = list(agent_action({}).keys())\n",
    "ACTION_TO_INDEX = {action: idx for idx, action in enumerate(ACTION_KEYS)}\n",
    "NUM_ACTIONS = len(ACTION_KEYS)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "# Paths - adjust to your setup\n",
    "image_folder = \"../data2/screenshots\"\n",
    "movement_json = \"../data2/movements.json\"\n",
    "\n",
    "with open(movement_json, \"r\") as f:\n",
    "    movements = json.load(f)\n",
    "ACTION_KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e97ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarioDataset(Dataset):\n",
    "    def __init__(self, image_folder, movements, frame_window=4):\n",
    "        self.image_folder = image_folder\n",
    "        self.movements = movements\n",
    "        self.frame_window = frame_window\n",
    "        self.frames = sorted(movements.keys())\n",
    "        self.valid_indices = list(range(frame_window, len(self.frames)))\n",
    "\n",
    "    def process_image(self, img, resize_to=(140, 114)):\n",
    "        img = img.resize(resize_to, Image.Resampling.LANCZOS)\n",
    "        img_array = np.array(img, dtype=np.float32)\n",
    "        img_tensor = torch.tensor(img_array).unsqueeze(0)\n",
    "        return img_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.valid_indices[idx]\n",
    "        imgs = []\n",
    "        for i in range(idx - self.frame_window, idx):\n",
    "            frame_key = self.frames[i]\n",
    "            img_path = os.path.join(self.image_folder, f\"d_{frame_key}.png\")\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            imgs.append(self.process_image(img))\n",
    "\n",
    "        state = torch.cat(imgs, dim=0)\n",
    "\n",
    "        frame_key = self.frames[idx]\n",
    "        keys = {k: v for k, v in self.movements[frame_key].items() if k != \"state\"}\n",
    "        actions_dict = agent_action(keys)\n",
    "        for a, value in reversed(actions_dict.items()):\n",
    "            if value:\n",
    "                action = a\n",
    "\n",
    "        reward = self.movements[frame_key][\"state\"].get(\"reward\", 0.0)\n",
    "\n",
    "        if idx + 1 < len(self.frames):\n",
    "            next_frame_key = self.frames[idx + 1]\n",
    "            next_img_path = os.path.join(self.image_folder, f\"d_{next_frame_key}.png\")\n",
    "            next_img = Image.open(next_img_path).convert(\"L\")\n",
    "            next_state = torch.cat([*imgs[1:], self.process_image(next_img)], dim=0)\n",
    "        else:\n",
    "            next_state = state\n",
    "\n",
    "        return state, action, reward, next_state\n",
    "\n",
    "def train(dataset, epochs=1, batch_size=256, learning_rate=1e-4):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    print(\"Dataloader created.\")\n",
    "    agent = Agent(\n",
    "    n_actions=NUM_ACTIONS,\n",
    "    input_dims=(4, 140, 114),\n",
    "    device=device,\n",
    "    num_envs=1,\n",
    "    agent_name=\"offline_agent\",\n",
    "    total_frames=len(dataset.frames),\n",
    "    testing=False,\n",
    "    imagex=114,\n",
    "    imagey=140,\n",
    "    )\n",
    "    for epoch in range(epochs):\n",
    "        for states, actions, rewards, next_states in dataloader:\n",
    "            actions_discrete = [ACTION_TO_INDEX[a] for a in actions]\n",
    "            actions = torch.tensor(actions_discrete, dtype=torch.long)\n",
    "\n",
    "            for s, a, r, ns in zip(states, actions, rewards, next_states):\n",
    "                agent.store_transition(\n",
    "                    state=s.numpy(),\n",
    "                    action=a.item(),\n",
    "                    reward=r.item(),\n",
    "                    next_state=ns.numpy(),\n",
    "                    done=False,\n",
    "                    stream=0,\n",
    "                    prio=True\n",
    "                )\n",
    "\n",
    "            for _ in range(agent.batch_size // batch_size):\n",
    "                agent.learn_call()\n",
    "\n",
    "        agent.save_model()\n",
    "        print(f\"Agent model saved at epoch {epoch + 1}.\")\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52cf127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader created.\n",
      "Agent model saved at epoch 1.\n"
     ]
    }
   ],
   "source": [
    "dataset = MarioDataset(image_folder=image_folder, movements=movements)\n",
    "train(dataset, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "NUM_ACTIONS = len(ACTION_KEYS)\n",
    "INPUT_DIMS = (4, 114, 140)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"offline_agent_0M.model\"          # Saved model name\n",
    "\n",
    "# --- Load Agent ---\n",
    "agent = Agent(\n",
    "    n_actions=NUM_ACTIONS,\n",
    "    input_dims=INPUT_DIMS,\n",
    "    device=DEVICE,\n",
    "    num_envs=1,\n",
    "    agent_name=\"offline_agent\",\n",
    "    total_frames=100000,\n",
    "    testing=True,\n",
    "    impala=True,\n",
    "    impoola=False,\n",
    ")\n",
    "\n",
    "agent.load_models(MODEL_NAME)\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# --- Helper: Load and preprocess 1 image ---\n",
    "def load_and_process_image(path):\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((140, 114), Image.Resampling.LANCZOS)\n",
    "    img_array = np.array(img, dtype=np.float32)\n",
    "    tensor = torch.tensor(img_array).unsqueeze(0)  # shape: (1, H, W)\n",
    "    return tensor\n",
    "\n",
    "# --- Prepare frames ---\n",
    "all_frames = [f for f in os.listdir(image_folder) if f.endswith(\".png\")]\n",
    "if len(all_frames) < 4:\n",
    "    raise ValueError(\"Not enough frames to make a prediction (need at least 4).\")\n",
    "\n",
    "# Iterate over all sequences of 4 consecutive frames\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "for i in range(len(all_frames) - 3):\n",
    "    frame_keys = [f.replace(\"d_\", \"\").replace(\".png\", \"\") for f in all_frames[i:i+4]]\n",
    "    frame_paths = [os.path.join(image_folder, f\"d_{k}.png\") for k in frame_keys]\n",
    "    frames = [load_and_process_image(p) for p in frame_paths]\n",
    "    state = torch.cat(frames, dim=0).unsqueeze(0).to(DEVICE)  # shape: (1, 4, 114, 140)\n",
    "\n",
    "    action_tensor = agent.choose_action(state)\n",
    "    action_index = action_tensor.item()\n",
    "    predicted_action = ACTION_KEYS[action_index]\n",
    "\n",
    "    # Get true action from movements.json (using last frame)\n",
    "    last_frame_key = frame_keys[-1]\n",
    "    if last_frame_key in movements:\n",
    "        keys = {k: v for k, v in movements[last_frame_key].items() if k != \"state\"}\n",
    "        true_actions = [action for action, is_pressed in agent_action(keys).items() if is_pressed]\n",
    "        true_action = next((action for action in ACTION_KEYS if action in true_actions), \"none\")\n",
    "    else:\n",
    "        true_action = \"UNKNOWN\"\n",
    "\n",
    "    print(f\"Frames {frame_paths[0]} to {frame_paths[3]} => Predicted: {predicted_action} | True: {true_action}\")\n",
    "    total_predictions += 1\n",
    "    if predicted_action == true_action:\n",
    "        correct_predictions += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correct_predictions / total_predictions * 100 if total_predictions > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
