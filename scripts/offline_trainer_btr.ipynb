{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45a4492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from btr.Agent import Agent\n",
    "\n",
    "def agent_action(filtered_keys):\n",
    "    sprint = filtered_keys.get(\"B\", False)\n",
    "    move_right = filtered_keys.get(\"Right\", False)\n",
    "    move_left = filtered_keys.get(\"Left\", False)\n",
    "\n",
    "    jump = filtered_keys.get(\"A\", False)\n",
    "    crouch = filtered_keys.get(\"Down\", False)\n",
    "    airborne = filtered_keys.get(\"One\", False)\n",
    "    sprint_left = move_left and sprint\n",
    "    sprint_right = move_right and sprint\n",
    "    jump_left = (move_left or sprint_left) and jump\n",
    "    jump_right = (move_right or sprint_right) and jump\n",
    "    stand_still = not any([move_right, move_left, jump, crouch, airborne, sprint_left, sprint_right, jump_left, jump_right])\n",
    "\n",
    "    remove_some = True\n",
    "    if remove_some:\n",
    "        if any([crouch, airborne, sprint_left, jump]):\n",
    "            stand_still = True\n",
    "            crouch = airborne = sprint_left = jump = False\n",
    "    return {\n",
    "        # \"jump\": jump,\n",
    "        # \"crouch\": crouch,\n",
    "        # \"airborne\": airborne,\n",
    "        # \"sprint_left\": sprint_left,\n",
    "        \"sprint_right\": sprint_right,\n",
    "        \"jump_left\": jump_left,\n",
    "        \"jump_right\": jump_right,\n",
    "        \"move_right\": move_right,\n",
    "        \"move_left\": move_left,\n",
    "        \"none\": stand_still,\n",
    "    }\n",
    "\n",
    "ACTION_KEYS = [\n",
    "                # \"crouch\",\n",
    "                # \"airborne\",\n",
    "                # \"sprint_left\",\n",
    "                \"sprint_right\",\n",
    "                \"jump_right\",\n",
    "                \"jump_left\",\n",
    "                \n",
    "                \"move_right\",\n",
    "                \"move_left\", \n",
    "                # \"jump\",\n",
    "                \"none\"]\n",
    "ACTION_TO_INDEX = {action: idx for idx, action in enumerate(ACTION_KEYS)}\n",
    "NUM_ACTIONS = len(ACTION_KEYS)\n",
    "\n",
    "class MarioDataset(Dataset):\n",
    "    def __init__(self, image_folder, movements, frame_window=4):\n",
    "        self.image_folder = image_folder\n",
    "        self.movements = movements\n",
    "        self.frame_window = frame_window\n",
    "        self.frames = sorted(movements.keys())\n",
    "        self.valid_indices = list(range(frame_window, len(self.frames)))\n",
    "\n",
    "    def process_image(self, img, resize_to=(140, 114)):\n",
    "        img = img.resize(resize_to, Image.Resampling.LANCZOS)\n",
    "        img_array = np.array(img, dtype=np.float32)\n",
    "        img_tensor = torch.tensor(img_array).unsqueeze(0)\n",
    "        return img_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.valid_indices[idx]\n",
    "        imgs = []\n",
    "        for i in range(idx - self.frame_window, idx):\n",
    "            frame_key = self.frames[i]\n",
    "            img_path = os.path.join(self.image_folder, f\"d_{frame_key}.png\")\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            imgs.append(self.process_image(img))\n",
    "\n",
    "        state = torch.cat(imgs, dim=0)\n",
    "\n",
    "        frame_key = self.frames[idx]\n",
    "        keys = {k: v for k, v in self.movements[frame_key].items() if k != \"state\"}\n",
    "        actions_dict = agent_action(keys)\n",
    "        for a, value in reversed(actions_dict.items()):\n",
    "            if value:\n",
    "                action = a\n",
    "\n",
    "        reward = self.movements[frame_key][\"state\"].get(\"reward\", 0.0)\n",
    "\n",
    "        if idx + 1 < len(self.frames):\n",
    "            next_frame_key = self.frames[idx + 1]\n",
    "            next_img_path = os.path.join(self.image_folder, f\"d_{next_frame_key}.png\")\n",
    "            next_img = Image.open(next_img_path).convert(\"L\")\n",
    "            next_state = torch.cat([*imgs[1:], self.process_image(next_img)], dim=0)\n",
    "        else:\n",
    "            next_state = state\n",
    "\n",
    "        return state, action, reward, next_state\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "def train(dataset, epochs=1, batch_size=32, learning_rate=0.0001):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    agent = Agent(\n",
    "        n_actions=NUM_ACTIONS,\n",
    "        input_dims=(4, 140, 114),\n",
    "        device=device,\n",
    "        num_envs=1,\n",
    "        agent_name=\"offline_agent\",\n",
    "        total_frames=50000,\n",
    "        testing=False,\n",
    "        batch_size=batch_size,\n",
    "        imagex=114,\n",
    "        imagey=140,\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for states, actions, rewards, next_states in dataloader:\n",
    "            actions_discrete = [ACTION_TO_INDEX[a] for a in actions]\n",
    "            actions = torch.tensor(actions_discrete, dtype=torch.long)\n",
    "\n",
    "            for s, a, r, ns in zip(states, actions, rewards, next_states):\n",
    "                agent.store_transition(\n",
    "                    state=s.numpy(),\n",
    "                    action=a.item(),\n",
    "                    reward=r.item(),\n",
    "                    next_state=ns.numpy(),\n",
    "                    done=False,\n",
    "                    stream=0,\n",
    "                    prio=True\n",
    "                )\n",
    "\n",
    "            for _ in range(agent.batch_size // batch_size):\n",
    "                agent.learn_call()\n",
    "\n",
    "    agent.save_model()\n",
    "    print(\"Agent model saved.\")\n",
    "    return agent\n",
    "\n",
    "# Paths - adjust to your setup\n",
    "image_folder = \"../data/screenshots\"\n",
    "movement_json = \"../data/movements.json\"\n",
    "\n",
    "with open(movement_json, \"r\") as f:\n",
    "    movements = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52cf127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent model saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<btr.Agent.Agent at 0x20e4a99a550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MarioDataset(image_folder=image_folder, movements=movements)\n",
    "train(dataset, epochs=5, batch_size=32, learning_rate=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3cd37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_0.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1004.png => Predicted: jump_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_100.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1008.png => Predicted: jump_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1000.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1012.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1004.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1016.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1008.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1020.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1012.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1024.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1016.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1028.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1020.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1032.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1024.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1036.png => Predicted: move_left | True: sprint_right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bartw\\OneDrive\\Documenten\\coding\\MarioBrosAI\\scripts\\btr\\Agent.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = T.tensor(observation, dtype=int).to(self.net.device)\n",
      "c:\\Users\\bartw\\OneDrive\\Documenten\\coding\\MarioBrosAI\\scripts\\btr\\Agent.py:301: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = T.tensor(observation, dtype=T.float).to(self.net.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1028.png to ../data/screenshots\\d_2025-05-05_17-59_frame_104.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1032.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1040.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1036.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1044.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_104.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1048.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1040.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1052.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1044.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1056.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1048.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1060.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1052.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1064.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1056.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1068.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1060.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1072.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1064.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1076.png => Predicted: none | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1068.png to ../data/screenshots\\d_2025-05-05_17-59_frame_108.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1072.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1080.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1076.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1084.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_108.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1088.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1080.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1092.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1084.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1096.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1088.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1100.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1092.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1104.png => Predicted: move_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1096.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1108.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1100.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1112.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1104.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1116.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1108.png to ../data/screenshots\\d_2025-05-05_17-59_frame_112.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1112.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1120.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1116.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1124.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_112.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1128.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1120.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1132.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1124.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1136.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1128.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1140.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1132.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1144.png => Predicted: none | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1136.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1148.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1140.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1152.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1144.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1156.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1148.png to ../data/screenshots\\d_2025-05-05_17-59_frame_116.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1152.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1160.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1156.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1164.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_116.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1168.png => Predicted: move_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1160.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1172.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1164.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1176.png => Predicted: none | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1168.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1180.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1172.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1184.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1176.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1188.png => Predicted: move_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1180.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1192.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1184.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1196.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1188.png to ../data/screenshots\\d_2025-05-05_17-59_frame_12.png => Predicted: move_right | True: move_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1192.png to ../data/screenshots\\d_2025-05-05_17-59_frame_120.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1196.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1200.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_12.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1204.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_120.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1208.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1200.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1212.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1204.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1216.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1208.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1220.png => Predicted: move_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1212.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1224.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1216.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1228.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1220.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1232.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1224.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1236.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1228.png to ../data/screenshots\\d_2025-05-05_17-59_frame_124.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1232.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1240.png => Predicted: none | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1236.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1244.png => Predicted: none | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_124.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1248.png => Predicted: move_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1240.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1252.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1244.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1256.png => Predicted: move_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1248.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1260.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1252.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1264.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1256.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1268.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1260.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1272.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1264.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1276.png => Predicted: move_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1268.png to ../data/screenshots\\d_2025-05-05_17-59_frame_128.png => Predicted: move_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1272.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1280.png => Predicted: none | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1276.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1284.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_128.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1288.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1280.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1292.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1284.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1296.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1288.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1300.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1292.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1304.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1296.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1308.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1300.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1312.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1304.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1316.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1308.png to ../data/screenshots\\d_2025-05-05_17-59_frame_132.png => Predicted: none | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1312.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1320.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1316.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1324.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_132.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1328.png => Predicted: move_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1320.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1332.png => Predicted: jump_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1324.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1336.png => Predicted: move_left | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1328.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1340.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1332.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1344.png => Predicted: move_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1336.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1348.png => Predicted: sprint_right | True: sprint_right\n",
      "Frames ../data/screenshots\\d_2025-05-05_17-59_frame_1340.png to ../data/screenshots\\d_2025-05-05_17-59_frame_1352.png => Predicted: sprint_right | True: sprint_right\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "from btr.Agent import Agent\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_ACTIONS = len(ACTION_KEYS)\n",
    "INPUT_DIMS = (4, 114, 140)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FRAME_DIR = \"../data/screenshots\"      # Path to your screenshots\n",
    "MOVEMENT_FILE = \"../data/movements.json\"  # Path to movements.json\n",
    "MODEL_NAME = \"offline_agent_0M.model\"          # Saved model name\n",
    "\n",
    "# --- Load movements ---\n",
    "with open(MOVEMENT_FILE, \"r\") as f:\n",
    "    movements = json.load(f)\n",
    "\n",
    "# --- Load Agent ---\n",
    "agent = Agent(\n",
    "    n_actions=NUM_ACTIONS,\n",
    "    input_dims=INPUT_DIMS,\n",
    "    device=DEVICE,\n",
    "    num_envs=1,\n",
    "    agent_name=\"offline_agent\",\n",
    "    total_frames=50000,\n",
    "    testing=True\n",
    ")\n",
    "\n",
    "agent.load_models(MODEL_NAME)\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# --- Helper: Load and preprocess 1 image ---\n",
    "def load_and_process_image(path):\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    img = img.resize((140, 114), Image.Resampling.LANCZOS)\n",
    "    img_array = np.array(img, dtype=np.float32)\n",
    "    tensor = torch.tensor(img_array).unsqueeze(0)  # shape: (1, H, W)\n",
    "    return tensor\n",
    "\n",
    "# --- Prepare frames ---\n",
    "all_frames = sorted([f for f in os.listdir(FRAME_DIR) if f.endswith(\".png\")])[:100]\n",
    "if len(all_frames) < 4:\n",
    "    raise ValueError(\"Not enough frames to make a prediction (need at least 4).\")\n",
    "\n",
    "# Iterate over all sequences of 4 consecutive frames\n",
    "for i in range(len(all_frames) - 3):\n",
    "    frame_keys = [f.replace(\"d_\", \"\").replace(\".png\", \"\") for f in all_frames[i:i+4]]\n",
    "    frame_paths = [os.path.join(FRAME_DIR, f\"d_{k}.png\") for k in frame_keys]\n",
    "    frames = [load_and_process_image(p) for p in frame_paths]\n",
    "    state = torch.cat(frames, dim=0).unsqueeze(0).to(DEVICE)  # shape: (1, 4, 114, 140)\n",
    "\n",
    "    action_tensor = agent.choose_action(state)\n",
    "    action_index = action_tensor.item()\n",
    "    predicted_action = ACTION_KEYS[action_index]\n",
    "\n",
    "    # Get true action from movements.json (using last frame)\n",
    "    last_frame_key = frame_keys[-1]\n",
    "    if last_frame_key in movements:\n",
    "        keys = {k: v for k, v in movements[last_frame_key].items() if k != \"state\"}\n",
    "        true_actions = [action for action, is_pressed in agent_action(keys).items() if is_pressed]\n",
    "        true_action = next((action for action in ACTION_KEYS if action in true_actions), \"none\")\n",
    "    else:\n",
    "        true_action = \"UNKNOWN\"\n",
    "\n",
    "    print(f\"Frames {frame_paths[0]} to {frame_paths[3]} => Predicted: {predicted_action} | True: {true_action}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
